[
  {
    "objectID": "analysis_main_final.html",
    "href": "analysis_main_final.html",
    "title": "Predicting New York City Home Prices",
    "section": "",
    "text": "New York City has an unusual housing market compared to most American cities. First, only about one-third of households own their homes1. Second, single-family homes are relatively rare in New York City – only one in eight housing units sold in 2021 were in this category.\nIn the most desirable neighborhoods in Manhattan and Brooklyn, single-family homes are mostly rowhomes, like the classic brownstone. In other parts of the city, homes in this category range from beachfront cottages to sprawling mansions. The rarity and diversity of single-family homes makes predicting their prices a challenging task. For companies in the real estate industry, a model that predicts prices accurately can be the difference between profit and going out of business.\nThe dataset compiled here incorporates information about each property, its location, and nearby services and amenities. In contrast, the Ames Iowa Housing dataset encountered in educational contexts consists mostly of the details of the home – number of bedrooms and bathrooms, features like basements and driveways, building materials etc.2 The location and amenities approach may be more useful in a city as large and geographically diverse as New York City.\n\n\n\nThe goal of the project is to build a model to predict sale prices of single-family homes in New York City using a combination of location features, areal features, and features of the property. The homes included in the training dataset should be move-in ready and sold on the open market, as those are the kinds of homes for which accurate pricing has the largest potential return for businesses.\n\n\n\nAll data are publicly available from https://opendata.cityofnewyork.us. The data has been sourced and compiled by the author.\nA few important considerations before getting into the data:\n\nAll the data used in this project are open data from city agencies, which may be less complete than commercial datasets.\nA large number of variables were explored for inclusion in the final set, but ultimately rejected. Some variables were relevant to only a small proportion of lots, while others had poor coverage or excessive missing values. Certain variables were highly correlated with the outcome, notably tax assessment data.\nScreening the homes in the dataset was an important task for this project, and could not be done automatically in R. The screening process is briefly described below.\n\n\n\nOutcome: Sale price\nPredictors:\n\nLocation:\n\nBorough\nLatitude and longitude\nDistance to city hall (used as measure of centrality)\n\nProperty attributes:\n\nLot area in square feet\nResidential area in square feet\nRatio of lot area to residential area\nNumber of floors\nYear built\nYear of last major alteration\nProperty landmarked or in historic district\n\nNearby amenities\n\nDistance to nearest…\n\nsubway station\nbike route\npark\nOpen Street\n\nNumber of each of the above within walking distance\nNumber of new housing units built nearby since 2010\nSchool quality ratings for zoned elementary and middle schools"
  },
  {
    "objectID": "analysis_main_final.html#wrangling-the-data",
    "href": "analysis_main_final.html#wrangling-the-data",
    "title": "Predicting New York City Home Prices",
    "section": "Wrangling the data",
    "text": "Wrangling the data\nThe first major data component is the NYC Department of Finance data on all property sales for 2021. This data is composed of five Excel spreadsheets, one for each borough.3 The spreadsheets have a common structure, so writing a function to import and select columns from them cuts down on redundant code.\n\nread_sales_data <- function(path) {\n  readxl::read_xlsx(\n    # Specify path\n    path = path,\n    # Specify tidy column names\n    col_names = c(\n      \"borough_num\",\n      \"neighborhood\",\n      \"bldg_class_cat\",\n      \"tax_class_now\",\n      \"block\",\n      \"lot\",\n      \"easement\",\n      \"bldg_class_now\",\n      \"address\",\n      \"apt\",\n      \"zip\",\n      \"res_unit_sale\",\n      \"comm_unit_sale\",\n      \"total_unit_sale\",\n      \"land_sq_ft\",\n      \"gross_sq_ft\",\n      \"year_built_sale\",\n      \"tax_class_sale\",\n      \"bldg_class_sale\",\n      \"sale_price\",\n      \"sale_date\"\n    ),\n    # Skip header\n    skip = 8\n  ) |>\n    dplyr::filter(\n      # Filter for single-family home sales...\n      bldg_class_cat == \"01 ONE FAMILY DWELLINGS\" &\n      # ...with a single unit sold...\n      total_unit_sale == 1\n    )\n}\n\n\nSales data\nAfter importing all five spreadsheets, we compile the data from all five boroughs into a single table.\nAn important next step is to create a Borough-Block-Lot (BBL) identifier for each row by combining the separate elements in the sales data. The BBL system is the city government’s method of uniquely identifying each lot in the entire city. We will use the BBL IDs to compile the data from the various sources that are available.\nEach unique sale is identified with a new column consisting of BBL plus date.\n\nErrors in the data\nThe sales data has several problems. First, there are several types of errors that must be screened for:\n\nMisclassified lots (condos in multi-unit buildings marked as single-family homes, empty lots classified as homes etc.)\nMissing information\nInaccurate information\n\nSales with these types of errors are excluded.\nSecond, there are a small number of houses that do not appear to be in habitable condition, and are sold for far less than market price. These houses were all discovered during the screening process described below, and are also excluded.\n\n\nSweetheart deals and transfers\nThe third type of problem with the data, and by far the largest, is that there are a large number of sales that are clearly not sold in arms-length sales on the open market. Including these sales in the dataset degrades the predictive power of any model attempting to predict market prices, so they should be excluded.\n\n\n\nNote the huge number of 0-dollar sales on a histogram of all single-family home prices (below).\n\n\n\n\n\nThe data clearly contains no-cost transfers and sweetheart deals (homes sold for $5000 or even $10) between family, friends, business entities, and so on.\n\n\nFiltering out non-arms-length sales\nThe market-rate prices we are predicting more specifically described as arm’s-length sales – sales where both parties are trying to maximize their advantage in the sale. In real estate, there are a number of different kinds of non-arms-length sales:\n\nAuctions\nBank-owned properties\nShort sales\nCash-for-homes services\n\nThese sales and others should be excluded from the dataset.\nWhile it is impossible to positively identify every sale in this category, we can create a filter to identify candidates. To do this, we use data scraped from live listings on Zillow4 to develop an understanding of what actual market sales look like.\n\n\n\n\n\nThe distribution of single-family homes listed for sale on Zillow looks similar to that of our sales data, though with a “thicker” upper tail.\nThe Zillow data allows us to answer two important questions:\n\nWhat is the minimum one can expect to pay for a house anywhere in the city? The sales for $5000 are obviously deals of some kind, but what about $100k sales? Based on the Zillow data, any house sold for under $250,000 is almost certainly not an arm’s-length sale and should be excluded.\nWhat is the range of prices one can expect to pay for a house in a given neighborhood? Prices are not uniform across the city, so the filter should be responsive to local sub-markets. Based on the Zillow data, for any given neighborhood, houses that are sold for less than 45% of the neighborhood median sale price are likely sales that should be excluded.\n\nWe build a filter that catches all homes under $250k and all homes that were sold for less than 45% of the median price in the local area. Two measures of “local area” are used – ZIP code and neighborhood – and produce somewhat different, yet overlapping, sets of results.\nScreening the filter results reveals that a small number of sales that appear to be on-market have been picked up by the filter, but overall the filter is reasonably effective.\n\n\nScreening sales manually\nIt is reasonable to assume that the filter did not catch all homes sold off-market. The next task is to manually screen a portion of the remaining sales by searching for the address on Zillow and other websites. Over time, an intuition of what counts as a non-arms-length sale can be developed. Broadly speaking, homes that have one or more of the following attributes are excluded:\n\nListed as an auction, short sale, bank-owned or real-estate-owned property, in foreclosure etc.\nListed with language indicating a fixer-upper or other problems\nShowing visible signs of deterioration or abandonment\nSold for substantially under for-sale or recently-sold homes in the area\nSold for less than a previously-recorded sale\n\nThe screening process is time-intensive, so not every home can be screened. The focus was put on homes under $500k, homes that stood out in some way during data exploration, and homes that were identified as over- or under-predictions at some point during the model building process. Some random screening of homes was done to counter some of the biases inherent in this method of screening. About 1000 sales were screened in this manner, and 450 sales were excluded based on the results.\n\n\nCapping the distribution\nAnother important filter for the data involves excluding homes over a certain price. The statistical reason for doing this is so that ultra-high-end outliers do not exert undue leverage during the modeling process. More conceptually, at some point in the price distribution, homes become out of reach of everyone except the ultra-wealthy, and thus the “market” for these homes is conceptually distinct from the market for homes sold for $500,000 to $1,000,000.\nFor this project, the prices will be capped at $10 million, a 40x multiple of the minimum price included. The decision to cap the prices here is ultimately arbitrary and may be higher than is truly useful – the principle of not discarding potentially useful data was important to the choice of where to cap.\n\n\n\n\n\nThe distribution of the screened and filtered sale price variable is similar in shape to both the original data and the Zillow data, meaning no extreme distortions were introduced during the process. An artifact visible in this graph that we can call the “million-dollar shelf” will show up more clearly in later graphs.\n\n\n\nPLUTO data\nThe next step is to import data from PLUTO files. “Primary Land Use Tax Lot Output”5 is the name for publicly available data for each tax lot (identified by a BBL ID) in the city. It contains location data, district data, and features of the buildings on the tax lot, like floor area and the year it was built. All of the features of the properties that were not found in the sales data are found here.\n\npluto_data <-\n  read_csv(\n    file = \"../data/pluto/Primary_Land_Use_Tax_Lot_Output__PLUTO_.csv\",\n    # Guess column type based on more rows than default\n    guess_max = 120000\n  ) |>\n  filter(bbl %in% sales_all_boroughs_filter_cap$bbl) |>\n  # Select columns and create tidy column names\n  select(\n    borough,\n    bbl,\n    address_pluto = address,\n    ct2010 = `census tract 2010`,\n    cb2010,\n    community_dist = `community board`,\n    council_dist = `council district`,\n    res_area = resarea,\n    num_floors = numfloors,\n    year_built_pluto = yearbuilt,\n    year_altered_1 = yearalter1,\n    year_altered_2 = yearalter2,\n    historic_dist = histdist,\n    landmark,\n    latitude,\n    longitude\n  )\n\nIn addition to variables directly from the data, three more variables are created here:\n\nFlag for historic properties: the property is a designated landmark or is part of a historic district\nThe ratio of lot size to residential area\nYear last altered: the year when the property last had major alterations that change its assessed tax value. If no alterations are recorded, the year built is used instead.\n\n\n\nNeighborhood Tabulation Areas\nNeighborhood Tabulation Areas6 are defined by the Department of Planning and are roughly equivalent to neighborhoods as commonly understood by city residents and those in the real estate industry. The NTA codes will be used as a short, convenient neighborhood identifier.\n\n\nDistance-and-count for nearby amenities\nTwo important aspects of nearby amenities are incorporated in this project: the distance to the nearest of the type, and the count of that type of amenity within walking distance. “Walking distance” is variously defined as 400m (1/4 mile) and 800m (1/2 mile), but for this project, we’ll split the difference and define it as 600m.\nTo quickly calculate distance-to-nearest and count-in-radius, this function will used.\n\ndist_and_count <- function(to_location, count_within_dist_m) {\n  # Returns row number of nearest feature to each BBL from nearest_to table\n  nearest_feature =\n    # Use bbl_sf every time\n    bbl_sf |>\n    st_nearest_feature(\n      y = to_location\n    )\n  \n  dist_to_loc_tbl = \n    # Use bbl_sf every time\n    bbl_sf |>\n    # Find distance to location and round\n    mutate(\n      dist_to_loc = \n        st_distance(\n          x = bbl_sf,\n          y = to_location[nearest_feature, ],\n          by_element = TRUE\n        ) |>\n        as.numeric() |>\n        round()\n    ) |>\n    # Create a tibble with BBL and corresponding distance\n    as_tibble() |>\n    select(\n      bbl,\n      dist_to_loc\n    )\n  \n  count_within_dist <-\n    # Use bbl_sf\n    bbl_sf |>\n    # Find whether each BBL is within dist_m meters of each object\n    st_is_within_distance(\n      y = to_location,\n      dist = count_within_dist_m,\n      sparse = FALSE\n    ) |>\n    # Sum across each row to find number TRUE for each BBL\n    rowSums() |>\n    # Convert to tibble\n    as_tibble_col(column_name = \"num_within_dist\")\n  \n  dist_and_count <-\n    count_within_dist |>\n    mutate(\n      # Add BBL IDs\n      bbl = dist_to_loc_tbl$bbl,\n      # Add distance to nearest\n      dist_to_nearest = dist_to_loc_tbl$dist_to_loc,\n      .before = num_within_dist\n    )\n  \n  return(\n    dist_and_count |>\n      distinct()\n  )\n}\n\nHere are the amenities used in this project.\n\nSubway stations7\nThe subway is vitally important for connecting far-flung neighborhoods to the central areas of the city (and to each other). But large parts of the city have no subway connections, which may lead to lower desirability and thus lower prices. A “subway station” here is defined as a series of parallel platforms that one or more subway services may use. For example, Union Square in Manhattan counts as three stations (4-5-6, L, N-Q-R-W).\n\n\nBike routes8\nBike routes are increasingly important to getting around New York City, with a “bike boom” occurring in 2020. They are attractive amenities, much like the subway. We can expect housing prices near bike routes to be higher on average, increasing with bike route density.\nBike routes are represented as a series of segments, with roughly one block per segment. The number-within-walking distance represents bike route density, all segments of all routes within 600 meters.\n\n\nParks9\nParks are synonymous with city living, offering public green space for all residents. Good nearby parks may be associated with higher home prices. Park types included here are neighborhood parks, playgrounds, and major parks. Greenstreets features, neighborhood gardens, beaches, and other kinds of minor parks are not included.\n\n\nOpen Streets10\nOpen Streets11 are a recent innovation in New York City: public streets that have been closed to motor vehicles as a way to increase the public space available to neighborhood residents. Much like parks, nearby Open Streets may be associated with higher home prices. Open Streets include any area designated an open street at any point in 2021.\n\n\n\nDistance to City Hall\nCity Hall is a good proxy for the center of the city, even though it is not geographically the center point. It is adjacent to the very wealthy areas of FiDi and Lower Manhattan, and the area has been a center of civic and commercial life for centuries.\n\n\nLocal housing construction\nDepartment of Buildings data for completed jobs since 2010.12 Completed housing jobs are included since there are two competing popular intuitions: housing construction either drives prices up through gentrification, or drives prices down by increasing the housing supply.\n“Housing jobs” can be new construction and alteration (adding units) and demolition (removing units). The net impact of these jobs is summed for each census tract, a small area that is a collection of adjacent blocks.\n\n\nSchool quality\nSchool quality is often seen as exerting a strong influence on housing prices, with the intuition being that higher prices are associated with better schools. In NYC, elementary and middle schools each have their own zone systems, while high schools operate on a competitive admissions system similar to colleges. Because high schoolers will only sometimes attend schools near their place of residence, only elementary and middle schools are included in the data.\nThe School Quality Guide13 data is used, specifically the Parental Quality survey data. The survey consists of 6 quality metrics that are averaged to obtain an overall quality score for each school. Then all schools serving a zone have that score averaged. Finally, the zone for each lot is found and the score from that zone assigned to the lot.\n\n\nFinal dataset\nAfter compiling all the above sources, we have the final dataset.\n\nsfh_prices <-\n  all_data |>\n  select(\n    # Identifiers\n    sale_id,\n    address,\n    bbl,\n    borough,\n    neighborhood,\n    nta_code,\n    # Outcome variable\n    sale_price,\n    # Predictor variables\n    sale_date,\n    land_sq_ft,\n    gross_sq_ft,\n    lot_to_res_ratio,\n    num_floors,\n    year_built = year_built_sale,\n    year_last_altered,\n    historic,\n    latitude,\n    longitude,\n    dist_to_city_hall,\n    dist_to_subway,\n    num_subway_600m,\n    dist_to_bike_route,\n    num_bike_route_600m,\n    dist_to_park,\n    num_parks_600m,\n    dist_to_open_street,\n    num_open_streets_600m,\n    net_units_tract,\n    schools_quality_elem,\n    schools_quality_middle\n  )"
  },
  {
    "objectID": "analysis_main_final.html#exploratory-data-analysis",
    "href": "analysis_main_final.html#exploratory-data-analysis",
    "title": "Predicting New York City Home Prices",
    "section": "Exploratory data analysis",
    "text": "Exploratory data analysis\nWe split the data into training and test sets before exploring it further. Splitting the data at this point prevents data leakage, a phenomenon where decisions are made that bias the model to the data on hand such that it does not generalize well to future data.\nThe training set consists of 3/4 of the data, with the remaining 1/4 set aside for testing. The exploratory analysis below is based soley on the training set.\n\n\n\n\nDistribution of prices by borough\nA histogram of sale prices (below) for each borough confirms that Manhattan’s sale prices are higher than other boroughs, but the number of single-family homes sold in Manhattan is very small.\n\n\n\n\n\n\n\nPrices at the neighborhood level\nNeighborhood-level median prices can give us an idea of how prices are distributed across the city at the local level.\n\n\n\n\n\nThe bubble graph above shows that there may be two (or more) distinct market segments represented in the data:\n\na “mainstream” market of neighborhoods with high sales volume and prices under $1 million, located in Queens, Staten Island, The Bronx, and parts of Brooklyn\na “high-end” market of neighborhoods with fewer sales and prices over $1 million, located in Manhattan and parts of Brooklyn and Queens\n\nThe segments are shown by the larger bubbles in the mainstream market and by the “elbow” in the graph, where the slope changes abruptly around $1 million. While this potential segmentation of the market will not be addressed in this project, it is useful to keep in mind while interpreting the model results.\n\n\nPrice vs. the predictors\nFor brevity, just the highlights from the full data exploration and visualization are shown in this section.\n\nDate of sale\nSeasonality is a strong feature of the median sale price. According to national data, prices are lowest in the first and last months of the year, and highest during the summer months.14 This trend is reflected in our data. (The offset of the peak from the summer months to early fall likely coincides with the post-COVID “return to office” around this time.) Note that it is a nonlinear trend, which along with other nonlinear trends will influence the types of models that will be selected in the model building section.\n\n\n\n\n\n\n\n\n\n\nLot and building area\nAs expected, prices increase along with both lot size and the square footage of the building on the lot. The price between price and lot size is basically linear above a certain threshold. But as shown on the graph of price vs. lot size (below left), lots under 2500 sq ft are found across the full range of prices. Presumably, location matters for small lots.\nIn contrast, there is a strongly nonlinear relationship between price and residential area. This finding corresponds to another finding (not shown) that homes with more floors tend to sell for higher prices.\n\n\n\n\n\n\n\n\n\n\nLatitude and longitude\nWhile the relationship between price and latitude shows some distinct nonlinearity, the relationship between price and longitude is especially pronounced, with a prominent hump around the middle of the range. This hump presumably represents the more expensive neighborhoods in Manhattan and Brooklyn, while other parts of the city to the east and west have dramatically lower home prices.\n\n\n\n\n\n\n\n\n\n\nDistance to City Hall\nThe relationship between price and distance to city hall is highly nonlinear. The “two-phase” shape of this graph is very striking: prices fall quickly as distance increases, but flatline around 10-12 km. The “million-dollar shelf” is very visible here.\n\n\n\n\n\n\n\nDistance to nearest subway\nOf all the variables representing the distance to the nearest amenity, the distance to the subway has the most pronounced and clear relationship to price. This relationship is graphed on an untransformed x-axis and a log-transformed x-axis for comparison. Almost all homes over $2 million are near subway stations, and the trend is for lower prices as distance increases.\nRelationships between price and other distance amenities were similar, but less pronounced. Notably, the relationship between price and distance to parks was basically flat, and the maximum distance was fairly short – NYC parks are be plentiful and well-distributed around the city.\nThe relationships between price and the counts of amenities nearby were similar: the more amenities nearby, the higher the price tends to be. Again, parks were the exception: the relationship was flat.\n\n\n\n\n\n\n\n\n\n\nSchool quality\nVisualizing school quality yields both expected and unexpected results. Elementary school quality is positively associated with prices and almost all homes sold for $2 million and over have better elementary schools nearby. But neither of these relationships hold true for middle school quality.\n\n\n\n\n\n\n\n\n\n\n\nCorrelation plot\nCorrelation plot of all variables. None of the variables are correlated with each other at a level higher than 0.80 (though year built and year last altered are at 0.80). Excessive correlation (which can violate model assumptions and lead to poor results) will not be an issue in the modeling process."
  },
  {
    "objectID": "analysis_main_final.html#building-the-predictive-model",
    "href": "analysis_main_final.html#building-the-predictive-model",
    "title": "Predicting New York City Home Prices",
    "section": "Building the predictive model",
    "text": "Building the predictive model\nWe will use the tidymodels framework for building and tuning the model. Tidymodels uses similar principles to the tidyverse to provide standard interfaces across many different model types. It uses an integrated workflow for all parts of the modeling process, from data preprocessing to tuning models to fitting the final model.\n\nSelecting one model from several\nThe nonlinear relationships uncovered in exploratory data analysis indicate that models that capture nonlinear effects will be more suitable for our data. Additionally, given that we have more than a handful of predictors, it is more efficient to use models with automatic feature selection, which will weight variables by relevance or importance during model training. This capability will avoid the need to manually specify predictors in the model recipe.\nWe will compare the performance of these four models in order to select one for tuning.\n\nLinear model: An ordinary least squares model, included to compare to the other models and not as a candidate.\nMARS model: A regression model that captures nonlinear relationships using spline features.\nBoosted trees with xgboost: A random forest that learns from the performance of previous trees.\nRules-based model with cubist: A model that uses ensembles of rules derived from “flattened” trees.\n\n\nSpecifying the models\nAll the models are initially specified to use the default settings for their engines, rather than having settings manually specified or determined with tuning.\n\n# LM model spec\nlm_spec <-\n  linear_reg() |>\n  set_mode(\"regression\") |>\n  set_engine(\"lm\")\n\n# MARS model spec\nearth_spec <- \n  mars() |>\n  set_mode(\"regression\") |> \n  set_engine(\"earth\")\n\n# Boosted tree model spec\nxgboost_spec <- \n  boost_tree() |>\n  set_mode(\"regression\") |> \n  set_engine(\"xgboost\")\n\n# Cubist model spec\ncubist_spec <- \n  cubist_rules() |> \n  set_engine(\"Cubist\")\n\n\n\nWriting a recipe for preprocessing\nIn tidymodels, preprocessing the data is done by writing “recipes”. All models can use the same recipe, as none of them have mutually-exclusive requirements for preprocessing.\n\nbase_recipe <-\n  # Specify the basic recipe\n  recipe(\n    formula = sale_price ~ .,\n    data = sfh_prices_train\n  ) |>\n  # Change variable roles to identifier, rather than predictors\n  update_role(c(\n    sale_id,\n    address,\n    bbl,\n    neighborhood,\n    nta_code\n  ),\n    new_role = \"identifier\"\n  ) |>\n  # Convert the borough variable to a factor\n  step_string2factor(all_of(\"borough\")) |>\n  # Convert sale dates into week-of-year\n  step_date(\n    one_of(\"sale_date\"),\n    features = \"week\",\n    keep_original_cols = FALSE\n  ) |>\n  # Convert the historic district indicator into an explicit numeric\n  step_mutate(\n    historic = as.numeric(historic)\n  ) |>\n  # Impute any missing values\n  step_impute_knn(all_numeric_predictors()) |>\n  # Create dummy variables for the borough variable, using one-hot encoding\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>\n  # Zero-variance filter\n  step_zv(all_predictors()) |>\n  # Correlation filter\n  step_corr(\n    all_predictors(),\n    threshold = 0.9\n  ) |>\n  # Normalize (center and scale) all predictors\n  step_normalize(all_predictors())\n\n\n\nDefining a cross-validation scheme\nOverfitting to the training set can be mitigated by using a resampling scheme to repeatedly test models generated during the training process. Ten-fold cross-validation, used here, splits the data randomly into ten subsets and holds one in reserve to validate the model fitted on the other nine. Cross-validation is repeated 10 times, holding each subset in reserve once in turn. The performance statistics generated during each round of cross-validation are averaged to produce a final metric for evaluating the model.\n\n\n\nComparing multiple models\nAll three nonlinear models substantially outperformed the linear model. The MARS model underperformed the others by a small margin, while the Cubist and boosted tree models were very close in both RMSE and R-squared.\nThe Cubist model will be selected for tuning, as it has a slight edge over the boosted tree model in consistency (i.e., smaller standard error), though either model would work here.\n\n\n# A tibble: 8 × 4\n  model        .metric       mean    std_err\n  <chr>        <chr>        <dbl>      <dbl>\n1 linear_reg   rmse    373563.    13664.    \n2 linear_reg   rsq          0.709     0.0180\n3 mars         rmse    308800.    14761.    \n4 mars         rsq          0.799     0.0198\n5 boost_tree   rmse    276004.    13874.    \n6 boost_tree   rsq          0.840     0.0180\n7 cubist_rules rmse    279250.    10639.    \n8 cubist_rules rsq          0.839     0.0130\n\n\n\n\n\n\n\n\n\nTuning the selected model\nThe Cubist model will be trained with 10 sets of these two parameters:\n\nNumber of committees: the number of iterations allowed for formulating and adjusting the rules\nNumber of neighbors: the number of nearby points used for adjusting the predictions produced by the model\n\nThe parameter sets are generated using a random grid search method.\n\n\nTuning results\nThe tuning results show that all candidate parameter sets outperformed the untuned model, some by about as 15%.\n\n\n# A tibble: 10 × 5\n   model        .metric    mean     n std_err\n   <chr>        <chr>     <dbl> <int>   <dbl>\n 1 cubist_rules rmse    244672.    10   7705.\n 2 cubist_rules rmse    244971.    10   6963.\n 3 cubist_rules rmse    245265.    10   7546.\n 4 cubist_rules rmse    245285.    10   7327.\n 5 cubist_rules rmse    245903.    10   7666.\n 6 cubist_rules rmse    249281.    10   6899.\n 7 cubist_rules rmse    252045.    10   6317.\n 8 cubist_rules rmse    253730.    10   9640.\n 9 cubist_rules rmse    256380.    10   9190.\n10 cubist_rules rmse    269865.    10   6236.\n\n\nWe select a model with an algorithm that favors a less complex model (in this case, fewer committees), allowing a performance loss of up to than 2% compared the best-performing model. The principle here is that a less complex model has a better chance of generalizing to the test set.\nThe model selected by this process has the following parameters:\n\n\n# A tibble: 1 × 8\n  committees neighbors .metric .estimator    mean std_err   .best .loss\n       <int>     <int> <chr>   <chr>        <dbl>   <dbl>   <dbl> <dbl>\n1         22         3 rmse    standard   249281.   6899. 244672.  1.88\n\n\nNote that the selected Cubist model performs substantially better than the untuned model, and has only 0.76% performance loss compared to the best candidate model produced by tuning.\nHere are the selected model’s performance metrics:\n\n\n# A tibble: 2 × 4\n  model        .metric       mean    std_err\n  <chr>        <chr>        <dbl>      <dbl>\n1 cubist_rules rmse    249281.    6899.     \n2 cubist_rules rsq          0.871    0.00955\n\n\n\n\n\n\n\nTesting the tuned model\nThe last step is to fit the selected model to the test set. The metrics for the test fit show that the model’s performance is comparable to the best model trained on the training set.\n\n\n# A tibble: 3 × 4\n  .metric .estimator  .estimate .config             \n  <chr>   <chr>           <dbl> <chr>               \n1 rmse    standard   259372.    Preprocessor1_Model1\n2 mae     standard   122738.    Preprocessor1_Model1\n3 rsq     standard        0.857 Preprocessor1_Model1\n\n\n\nVariable importance\nBased on the variable importance plot for the fitted model, location (both absolute and in relationship to city hall), building and lot area, are the most important variables. This finding makes intuitive sense, as location and size of homes are the most heavily-promoted details in real estate listings. Of all the measures of nearby amenities, distance to the nearest subway station is the most important.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredictions and residuals\nThe predicted-actual plot (left) shows that the fitted model has a slight bias toward overpredict prices throughout the distribution, though the relationship is generally linear and compact. Further rounds of modeling could resolve this issue.\nThe prediction-residual plot (right) shows that, as expected, the residuals tend to increase in magnitude as prices increase. The distribution in the “mainstream” segment identified during visualization (under $1 million) is compact and symmetrical, while the distribution in the “high-end” segment is much more diffuse and has notable outliers. The divergence between the median prediction and the upper range may be an indicator that there are latent “rules” for the high-end housing market that do not match the median market.\n\n\n\n\n\n\n\n\n\n\nPerformance across the price distribution\nThe graph on the left shows the ratio of residuals to actual prices. Ideally, the points on this graph would be distributed symmetrically around the x-axis (dotted blue line) and have a trend line (red) with a slope of 0. The graph shows that the distribution is asymmetrical with respect to the x-axis, and in fact tends to under-predict prices overall. The non-zero slope of the trend line indicates that the model goes from under-predicting in the low end of the price distribution to over-predicting in the high end.\nThe graph on the right is the absolute-value version of the graph on the left. The mean absolute residual (deviation from perfect prediction) is show by the blue line, and the red trend line shows that the model tends to be less accurate as prices increase. The model clearly has some systematic bias in its predictions that could be accounted for in the future."
  },
  {
    "objectID": "analysis_main_final.html#discussion",
    "href": "analysis_main_final.html#discussion",
    "title": "Predicting New York City Home Prices",
    "section": "Discussion",
    "text": "Discussion\nThe predictions from this model are reasonably good. Considering the range of prices included in the model, an RMSE of $259k and a mean absolute error of $122k are reasonable. The model performs especially well in the most dense regions of the dataset, with properties from $400k to $1.5 million.\nPredicting home prices from a combination of property attributes and location and area attributes has been shown to be a reasonably good method. The nearby amenities have not contributed much individually to the model, with the location and home size predictors being far more important. But the importance plot shows that they do collectively contribute to better performance. Refining this approach will likely yield useful results."
  },
  {
    "objectID": "analysis_main_final.html#next-steps",
    "href": "analysis_main_final.html#next-steps",
    "title": "Predicting New York City Home Prices",
    "section": "Next steps",
    "text": "Next steps\nRecommendations for the next steps in developing this model:\n\nExpand the dataset by incorporating more variables from commercial datasets and other open sources.\nAssess whether dividing the full range of sale prices into multiple market segments and creating models for each segment produces better results.\nCreate standardized methods for removing homes sold under market value from the dataset.\nIterate on the model building process to improve performance, tune other models besides the Cubist model, and use more intensive tuning methods to find any potential better-performing models."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my portfolio!",
    "section": "",
    "text": "The nav bar above will take you where you want to go."
  },
  {
    "objectID": "leaflet_maps_sfh_2021.html",
    "href": "leaflet_maps_sfh_2021.html",
    "title": "Maps: Single-family home sales in 2021",
    "section": "",
    "text": "Sales by census tract\n\n\n\n\n\n\n\n\nIndividual sales"
  },
  {
    "objectID": "leaflet_maps.html",
    "href": "leaflet_maps.html",
    "title": "Housing Maps",
    "section": "",
    "text": "all_data <-\n  read_csv(\n    file = \"../data/nyc_sfh_prices_all_data.csv\",\n    guess_max = 12000\n  )\n\nRows: 12817 Columns: 56\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (12): sale_id, neighborhood, address, bldg_class_cat, bldg_class_now, b...\ndbl  (40): bbl, zip, borough_num, tax_class_now, block, lot, res_unit_sale, ...\nlgl   (3): easement, apt, historic\ndttm  (1): sale_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data$fips_ct_2010 <- as.character(all_data$fips_ct_2010)\n\n\nnabe_tabu_areas <-\n  st_read(\"../data/nta/geo_export_0b20c41f-8213-4aca-a93e-535aa523680e.shp\")\n\nReading layer `geo_export_0b20c41f-8213-4aca-a93e-535aa523680e' from data source `C:\\Users\\Office\\Documents\\R\\Projects\\NYC Housing Megaproject\\data\\nta\\geo_export_0b20c41f-8213-4aca-a93e-535aa523680e.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 195 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS84(DD)\n\n\n\ntidycensus::census_api_key(\"f39c06acef3a731d587edd040f6791072a394334\")\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\nnyc_tract_geometry <-\n  tidycensus::get_decennial(\n    state = \"NY\",\n    county = c(\n      \"Bronx\",\n      \"Kings\",\n      \"New York\",\n      \"Queens\",\n      \"Richmond\"\n    ),\n    geography = \"tract\",\n    variables = \"H001001\",\n    geometry = TRUE,\n    year = 2010\n  )\n\nGetting data from the 2010 decennial Census\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\nUsing Census Summary File 1\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |========================================================              |  81%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n# Transform to leaflet-compatible CRS to avoid warnings.\nnyc_tract_geometry <-\n  st_transform(\n    nyc_tract_geometry,\n    \"+no_defs +datum=WGS84 +proj=longlat\"\n  )\n\n\npoint_map_data <-\n  all_data |>\n  # Most recent sales first\n  arrange(\n    sale_date |>\n      desc()\n  ) |>\n  # Preserve only one sale per BBL\n  # arrange() call above preserves most recent\n  distinct(\n    bbl,\n    .keep_all = TRUE\n  )\n\npoint_map_data <-\n  point_map_data |>\n  mutate(\n    # Create legible neighborhood names\n    address_title = \n      str_to_title(address),\n    # Create legible neighborhood names\n    neighborhood_title = \n      str_to_title(neighborhood),\n    # Format sale prices to readable style\n    sale_price_dollar =\n      sale_price |>\n      scales::dollar(),\n    # Create label\n    label = \n      str_c(\n        \"<p> <b>\",\n        address_title,\n        \"</b> </br>\",\n        \"Neighborhood:\",\n        neighborhood_title,\n        \"</br>\",\n        \"Sale price:\",\n        sale_price_dollar,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of all sales.\n\nleaflet(\n    point_map_data,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addCircles(\n    ~longitude,\n    ~latitude,\n    color =\n      ~colorBin(\n        palette = \"viridis\",\n        log(sale_price)\n      )(log(sale_price)),\n    weight = 5,\n    opacity = 1.0,\n    popup = ~label\n  )\n\n\n\n\n\nCreate data table of median sale prices by census tract.\n\nmedian_price_by_tract <-\n  all_data |>\n  group_by(fips_ct_2010) |>\n  summarize(\n    median_price_tract = median(sale_price),\n    num_homes_sold = n()\n  )\n\nmedian_price_by_tract_sf <-\n  nyc_tract_geometry |>\n  left_join(\n    median_price_by_tract,\n    by = c(\"GEOID\" = \"fips_ct_2010\")\n  ) |>\n  filter(\n    !is.na(median_price_tract)\n  ) |>\n  filter(num_homes_sold >= 1) |>\n  mutate(\n    log_median_price_tract = log10(median_price_tract)\n  )\n\nCreate HTML labels for median price map.\n\nmedian_price_by_tract_sf <-\n  median_price_by_tract_sf |>\n  mutate(\n    # Format price column as dollar values\n    median_price_tract_label =\n      median_price_tract |>\n      scales::dollar(),\n    # Create HTML labels\n    label =\n      str_c(\n        \"<p> <b>\",\n        NAME,\n        \"</b> </br>\",\n        \"Homes sold:\",\n        num_homes_sold,\n        \"</br>\",\n        \"Median sale price:\",\n        median_price_tract_label,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of median sale prices by census tract.\n\nleaflet(\n    median_price_by_tract_sf,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addPolygons(\n    color = \"#444444\",\n    weight = 1,\n    smoothFactor = 0.5,\n    opacity = 1.0,\n    fillOpacity = 0.5,\n    fillColor =\n      ~colorBin(\n        palette = \"viridis\",\n        log_median_price_tract\n      )(log_median_price_tract),\n    highlightOptions =\n      highlightOptions(\n        color = \"white\",\n        weight = 2,\n        bringToFront = TRUE\n      ),\n    popup = ~label\n  )\n\n\n\n\n\nCreate data table of median sale prices by census tract.\n\nmedian_price_by_nta <-\n  all_data |>\n  group_by(nta_code) |>\n  summarize(\n    median_price_nta = median(sale_price),\n    num_homes_sold = n()\n  )\n\nnabe_tabu_areas <-\n  st_transform(\n    nabe_tabu_areas,\n    \"+no_defs +datum=WGS84 +proj=longlat\"\n  )\n\nmedian_price_by_nta_sf <-\n  nabe_tabu_areas |>\n  left_join(\n    median_price_by_nta,\n    by = c(\"ntacode\" = \"nta_code\")\n  ) |>\n  filter(\n    !is.na(median_price_nta)\n  ) |>\n  filter(num_homes_sold >= 1) |>\n  mutate(\n    log_median_price_nta = log10(median_price_nta)\n  )\n\nCreate HTML labels for median price map.\n\nmedian_price_by_nta_sf <-\n  median_price_by_nta_sf |>\n  mutate(\n    # Format price column as dollar values\n    median_price_nta_label =\n      median_price_nta |>\n      scales::dollar(),\n    # Create HTML labels\n    label =\n      str_c(\n        \"<p> <b>\",\n        ntaname,\n        \"</b> </br>\",\n        \"Homes sold:\",\n        num_homes_sold,\n        \"</br>\",\n        \"Median sale price:\",\n        median_price_nta_label,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of median sale prices by census tract.\n\nleaflet(\n    median_price_by_nta_sf,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addPolygons(\n    color = \"#444444\",\n    weight = 1,\n    smoothFactor = 0.5,\n    opacity = 1.0,\n    fillOpacity = 0.5,\n    fillColor =\n      ~colorBin(\n        palette = \"viridis\",\n        log_median_price_nta\n      )(log_median_price_nta),\n    highlightOptions =\n      highlightOptions(\n        color = \"white\",\n        weight = 2,\n        bringToFront = TRUE\n      ),\n    popup = ~label\n  )"
  },
  {
    "objectID": "leaflet_maps_co-ops_2021.html",
    "href": "leaflet_maps_co-ops_2021.html",
    "title": "Housing Maps",
    "section": "",
    "text": "all_data <-\n  read_csv(\n    file = \"../data/nyc_sfh_prices_all_data.csv\",\n    guess_max = 12000\n  )\n\nRows: 12817 Columns: 56\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (12): sale_id, neighborhood, address, bldg_class_cat, bldg_class_now, b...\ndbl  (40): bbl, zip, borough_num, tax_class_now, block, lot, res_unit_sale, ...\nlgl   (3): easement, apt, historic\ndttm  (1): sale_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nall_data$fips_ct_2010 <- as.character(all_data$fips_ct_2010)\n\n\nnabe_tabu_areas <-\n  st_read(\"../data/nta/geo_export_0b20c41f-8213-4aca-a93e-535aa523680e.shp\")\n\nReading layer `geo_export_0b20c41f-8213-4aca-a93e-535aa523680e' from data source `C:\\Users\\Office\\Documents\\R\\Projects\\NYC Housing Megaproject\\data\\nta\\geo_export_0b20c41f-8213-4aca-a93e-535aa523680e.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 195 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS84(DD)\n\n\n\ntidycensus::census_api_key(\"f39c06acef3a731d587edd040f6791072a394334\")\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\nnyc_tract_geometry <-\n  tidycensus::get_decennial(\n    state = \"NY\",\n    county = c(\n      \"Bronx\",\n      \"Kings\",\n      \"New York\",\n      \"Queens\",\n      \"Richmond\"\n    ),\n    geography = \"tract\",\n    variables = \"H001001\",\n    geometry = TRUE,\n    year = 2010\n  )\n\nGetting data from the 2010 decennial Census\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\nUsing Census Summary File 1\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n# Transform to leaflet-compatible CRS to avoid warnings.\nnyc_tract_geometry <-\n  st_transform(\n    nyc_tract_geometry,\n    \"+no_defs +datum=WGS84 +proj=longlat\"\n  )\n\n\npoint_map_data <-\n  all_data |>\n  # Most recent sales first\n  arrange(\n    sale_date |>\n      desc()\n  ) |>\n  # Preserve only one sale per BBL\n  # arrange() call above preserves most recent\n  distinct(\n    bbl,\n    .keep_all = TRUE\n  )\n\npoint_map_data <-\n  point_map_data |>\n  mutate(\n    # Create legible neighborhood names\n    address_title = \n      str_to_title(address),\n    # Create legible neighborhood names\n    neighborhood_title = \n      str_to_title(neighborhood),\n    # Format sale prices to readable style\n    sale_price_dollar =\n      sale_price |>\n      scales::dollar(),\n    # Create label\n    label = \n      str_c(\n        \"<p> <b>\",\n        address_title,\n        \"</b> </br>\",\n        \"Neighborhood:\",\n        neighborhood_title,\n        \"</br>\",\n        \"Sale price:\",\n        sale_price_dollar,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of all sales.\n\nleaflet(\n    point_map_data,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addCircles(\n    ~longitude,\n    ~latitude,\n    color =\n      ~colorBin(\n        palette = \"viridis\",\n        log(sale_price)\n      )(log(sale_price)),\n    weight = 5,\n    opacity = 1.0,\n    popup = ~label\n  )\n\n\n\n\n\nCreate data table of median sale prices by census tract.\n\nmedian_price_by_tract <-\n  all_data |>\n  group_by(fips_ct_2010) |>\n  summarize(\n    median_price_tract = median(sale_price),\n    num_homes_sold = n()\n  )\n\nmedian_price_by_tract_sf <-\n  nyc_tract_geometry |>\n  left_join(\n    median_price_by_tract,\n    by = c(\"GEOID\" = \"fips_ct_2010\")\n  ) |>\n  filter(\n    !is.na(median_price_tract)\n  ) |>\n  filter(num_homes_sold >= 1) |>\n  mutate(\n    log_median_price_tract = log10(median_price_tract)\n  )\n\nCreate HTML labels for median price map.\n\nmedian_price_by_tract_sf <-\n  median_price_by_tract_sf |>\n  mutate(\n    # Format price column as dollar values\n    median_price_tract_label =\n      median_price_tract |>\n      scales::dollar(),\n    # Create HTML labels\n    label =\n      str_c(\n        \"<p> <b>\",\n        NAME,\n        \"</b> </br>\",\n        \"Homes sold:\",\n        num_homes_sold,\n        \"</br>\",\n        \"Median sale price:\",\n        median_price_tract_label,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of median sale prices by census tract.\n\nleaflet(\n    median_price_by_tract_sf,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addPolygons(\n    color = \"#444444\",\n    weight = 1,\n    smoothFactor = 0.5,\n    opacity = 1.0,\n    fillOpacity = 0.5,\n    fillColor =\n      ~colorBin(\n        palette = \"viridis\",\n        log_median_price_tract\n      )(log_median_price_tract),\n    highlightOptions =\n      highlightOptions(\n        color = \"white\",\n        weight = 2,\n        bringToFront = TRUE\n      ),\n    popup = ~label\n  )\n\n\n\n\n\nCreate data table of median sale prices by census tract.\n\nmedian_price_by_nta <-\n  all_data |>\n  group_by(nta_code) |>\n  summarize(\n    median_price_nta = median(sale_price),\n    num_homes_sold = n()\n  )\n\nnabe_tabu_areas <-\n  st_transform(\n    nabe_tabu_areas,\n    \"+no_defs +datum=WGS84 +proj=longlat\"\n  )\n\nmedian_price_by_nta_sf <-\n  nabe_tabu_areas |>\n  left_join(\n    median_price_by_nta,\n    by = c(\"ntacode\" = \"nta_code\")\n  ) |>\n  filter(\n    !is.na(median_price_nta)\n  ) |>\n  filter(num_homes_sold >= 1) |>\n  mutate(\n    log_median_price_nta = log10(median_price_nta)\n  )\n\nCreate HTML labels for median price map.\n\nmedian_price_by_nta_sf <-\n  median_price_by_nta_sf |>\n  mutate(\n    # Format price column as dollar values\n    median_price_nta_label =\n      median_price_nta |>\n      scales::dollar(),\n    # Create HTML labels\n    label =\n      str_c(\n        \"<p> <b>\",\n        ntaname,\n        \"</b> </br>\",\n        \"Homes sold:\",\n        num_homes_sold,\n        \"</br>\",\n        \"Median sale price:\",\n        median_price_nta_label,\n        \"</p>\",\n        sep = \" \"\n      )\n  )\n\nLeaflet map of median sale prices by census tract.\n\nleaflet(\n    median_price_by_nta_sf,\n    width = 1280,\n    height = 720\n  ) |>\n  addProviderTiles(\n    providers$Stamen.Toner,\n    options = \n    tileOptions(\n      minZoom = 10, # furthest\n      maxZoom = 18 # closest\n    )\n  ) |>\n  addPolygons(\n    color = \"#444444\",\n    weight = 1,\n    smoothFactor = 0.5,\n    opacity = 1.0,\n    fillOpacity = 0.5,\n    fillColor =\n      ~colorBin(\n        palette = \"viridis\",\n        log_median_price_nta\n      )(log_median_price_nta),\n    highlightOptions =\n      highlightOptions(\n        color = \"white\",\n        weight = 2,\n        bringToFront = TRUE\n      ),\n    popup = ~label\n  )"
  },
  {
    "objectID": "leaflet_maps_condos_2021.html",
    "href": "leaflet_maps_condos_2021.html",
    "title": "Maps: Condominium sales in 2021",
    "section": "",
    "text": "Sales by census tract"
  },
  {
    "objectID": "leaflet_maps_coops_2021.html",
    "href": "leaflet_maps_coops_2021.html",
    "title": "Maps: Cooperative apartment sales in 2021",
    "section": "",
    "text": "Sales by census tract"
  }
]